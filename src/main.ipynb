{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL.Image import DecompressionBombError\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import praw,requests\n",
    "import psaw\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Checks if two images are identical, returns true if they are, returns true if a file is blank\n",
    "def compare2images(original,duplicate):\n",
    "    if original is None or duplicate is None:\n",
    "        return True #delete emtpy pictures\n",
    "    if original.shape == duplicate.shape:\n",
    "        #print(\"The images have same size and channels\")\n",
    "        difference = cv2.subtract(original, duplicate)\n",
    "        b, g, r = cv2.split(difference)\n",
    "        if cv2.countNonZero(b) == 0 and cv2.countNonZero(g) == 0 and cv2.countNonZero(r) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#A simple progress bar for transparency on the 20000 image processing tasks\n",
    "def progress(purpose,currentcount, maxcount):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(\"{}: {:.1f}%\".format(purpose,(100/(maxcount-1)*currentcount)))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#custom image data generator following this example https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
    "def custom_file_image_generator(inputPath,bs,mode=\"train\",aug=None, max = 1, frompath=\"picsnew\"):\n",
    "    f = open(inputPath, \"r\")\n",
    "    while True:\n",
    "        images = []\n",
    "        labels = []\n",
    "        while len(images)<bs:\n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                f.seek(0)\n",
    "                line = f.readline()\n",
    "                # if we are evaluating we should now break from our\n",
    "                # loop to ensure we don't continue to fill up the\n",
    "                # batch from samples at the beginning of the file\n",
    "                if mode == \"eval\":\n",
    "                    break\n",
    "            label = int(line.split(\".\")[0].split(\"_\")[0])\n",
    "            stripped = line.strip('\\n')\n",
    "            image = plt.imread(f\"{frompath}{stripped}\")\n",
    "            #Removes alpha channel\n",
    "            image = np.float32(image)[:,:,:3]\n",
    "            #Neceesary resizing to avoid PIL pixel cap\n",
    "            while image.shape[0] * image.shape[1]>89478485:\n",
    "                image = cv2.resize(image, (0,0), fx=0.5, fy=0.5)\n",
    "            cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "            images.append(image)\n",
    "            labels.append(label/max)\n",
    "        labels = np.asarray(labels).T\n",
    "        yield(np.asarray(images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Set up Reddit api for downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Set up API keys from .gitignored file\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)['keys']\n",
    "\n",
    "# Sign into Reddit using API Key\n",
    "reddit = praw.Reddit(user_agent=\"Downloading images from r/art for a machine learning project\",\n",
    "                     client_id=config['client_id'],\n",
    "                     client_secret=config['client_secret'],\n",
    "                     username=config['username'],\n",
    "                     password=config['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Downloading pictures from Reddit r/art using PSAW and PRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#187mb for 200 pics, approx 18.7gb for 20000\n",
    "#Time periods to choose to download from\n",
    "Jan12018 = int(dt.datetime(2018,1,1).timestamp())\n",
    "Jan12019 = int(dt.datetime(2019,1,1).timestamp())\n",
    "Jan12020 = int(dt.datetime(2020,1,1).timestamp())\n",
    "Jan12021 = int(dt.datetime(2021,1,1).timestamp())\n",
    "\n",
    "#Pass a PRAW instance into PSAW so that scores are available\n",
    "api = psaw.PushshiftAPI(reddit)\n",
    "#Number of posts to try and download\n",
    "n = 30000\n",
    "#Path to download to\n",
    "dlpath = \"pics2/\"\n",
    "\n",
    "print(\"Looking for posts using Pushshift...\")\n",
    "#this step takes a while\n",
    "posts = list(api.search_submissions(after = Jan12019, before=Jan12020, subreddit='art', limit = n*10))\n",
    "numpostsfound = len(posts)\n",
    "print(f\"Number of posts found:  {numpostsfound}\")\n",
    "counter = 0\n",
    "\n",
    "for post in posts:\n",
    "    if post.score>1:\n",
    "        progress(\"Downloading\",counter,numpostsfound)\n",
    "        counter +=1\n",
    "        url = (post.url)\n",
    "        #Save score for ML training, and post id for unique file names\n",
    "        file_name = str(post.score) + \"_\" + str(post.id) + \".jpg\"\n",
    "        try:\n",
    "            #use requests to get image\n",
    "            r = requests.get(url)\n",
    "            fullfilename = dlpath + file_name\n",
    "            #save image\n",
    "            with open(fullfilename,\"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        except (\n",
    "            requests.ConnectionError,\n",
    "            requests.exceptions.ReadTimeout,\n",
    "            requests.exceptions.Timeout,\n",
    "            requests.exceptions.ConnectTimeout,\n",
    "        ) as e:\n",
    "            print(e)\n",
    "            \n",
    "files = [f for f in os.listdir(dlpath) if os.path.isfile(os.path.join(dlpath, f))]\n",
    "#Number of files downloaded not always the same as requested due to connection errors\n",
    "print(f'\\nNumber of files downloaded: {len(files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing code that removes pictures that are deleted/corrupt\n",
    "Might need to run multiple times if low on ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Number of files: 11377\n",
      "Deleting bad files: 100.0%\n",
      "Final Number of files: 11364\n"
     ]
    }
   ],
   "source": [
    "#Path to delete bad pictures from\n",
    "path = \"pics2/\"\n",
    "\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "cull = []\n",
    "counter = 0\n",
    "length = len(files)\n",
    "print(f\"Original Number of files: {length}\")\n",
    "#Template of a bad picture\n",
    "deletedtemplate = cv2.imread(\"exampledeleted.jpg\")\n",
    "deletedtemplate2 = cv2.imread(\"exampledeleted2.jpg\")\n",
    "for file in files:\n",
    "    progress(\"Deleting bad files\",counter,length)\n",
    "    counter+=1\n",
    "    fullfilename = path + file\n",
    "    candidate = cv2.imread(fullfilename)\n",
    "    #if it's the same picture as the template or the picture is None\n",
    "    if compare2images(deletedtemplate,candidate) or compare2images(deletedtemplate2,candidate):\n",
    "        #delete\n",
    "        os.remove(fullfilename)\n",
    "files2 = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "print(f\"\\nFinal Number of files: {len(files2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Preprocessing code that corrects grayscale images to RGB and rescales pictures to have maximum width or height of 1000\n",
    "If I ran nn training with large images, it would take too long, and if I ran on google colab,\n",
    "I wouldn't have the drive space for all the pictrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Path being read from\n",
    "path = 'pics2/'\n",
    "#Path writing to\n",
    "path2 = 'picsfix/'\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "length = len(files)\n",
    "counter = 0\n",
    "failures = []\n",
    "for file in files:\n",
    "    try:\n",
    "        progress(\"Resizing and fixing pictures\",counter,length)\n",
    "        #OpenCV doesn't open jpegs\n",
    "        img = plt.imread(f'{path}{file}')\n",
    "        if len(img.shape) <3:\n",
    "            # print(file)\n",
    "            # print(img.shape)\n",
    "            img= cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "            #Resize to 1000 max\n",
    "        largestdim = max(img.shape)\n",
    "        targetlargestdim = 1000\n",
    "        scaling= targetlargestdim / largestdim\n",
    "        #print(scaling)\n",
    "        if(scaling<1): #If image is already smaller, don't bother upscaling\n",
    "            smaller = cv2.resize(img, (0,0), fx=scaling, fy=scaling)\n",
    "        else:\n",
    "            smaller = img\n",
    "        filename = path2+file\n",
    "        plt.imsave(filename,smaller)\n",
    "        counter += 1\n",
    "    except DecompressionBombError as e:\n",
    "        print(file)\n",
    "        print(\"Decomp error\")\n",
    "print(\"\\ndone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot histogram of scores to see how bad the bias towards lower scores is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"picsfix2\"\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "numpics = len(files)\n",
    "labelsall = []\n",
    "for file in files:\n",
    "    labelsall.append(int(file.split(\".\")[0].split(\"_\")[0]))\n",
    "#print(labelsall)\n",
    "plt.hist(labelsall)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.title(\"Post score distribution, log scale\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Split files into training and testing sets and write the names of files to txt files\n",
    "I'm following [this guide](https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/)\n",
    "and using a file reader to reset the index to 0 seemed like the easiest solution to mimic what the author set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Path of pictures to split and write txts for\n",
    "path = \"picsfix2/\"\n",
    "trainingpath = \"training.txt\"\n",
    "testingpath = \"testing.txt\"\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "#randomize to avoid passing pictures to the neural net in alphabetical order\n",
    "random.shuffle(files)\n",
    "#print(files)\n",
    "trainindex = int(np.round(0.8 * len(files)))\n",
    "training = files[0:trainindex]\n",
    "testing = files[trainindex:]\n",
    "with open(trainingpath, 'w') as f:\n",
    "    for item in training:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open(testingpath, 'w') as f:\n",
    "    for item in testing:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 8. Actual neural net training using Convolutional Neural Net\n",
    "I didn't have enough ram to train locally, so I ended porting to Google Colab and training there.\n",
    "The trainin has not been succesful so far, and I haven't taken the time to diagnose why yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score: 54157\n",
      "Epoch 1/12\n",
      " 1443/14918 [=>............................] - ETA: 1:37:21 - loss: 0.0014 - acc: 0.0049"
     ]
    }
   ],
   "source": [
    "#Path of preprocessed pictures\n",
    "path = \"picsfix2/\"\n",
    "#Paths of training and testing txts that have file names\n",
    "trainPath = 'training.txt'\n",
    "testpath = 'testing.txt'\n",
    "#Get all file names\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "numpics = len(files)\n",
    "labelsall = []\n",
    "for file in files:\n",
    "    labelsall.append(int(file.split(\".\")[0].split(\"_\")[0]))\n",
    "highestScore = max(labelsall)\n",
    "print(f'Highest score: {highestScore}')\n",
    "\n",
    "\n",
    "#Store all image arrays and image names in a list\n",
    "input_shape=(None, None,3)\n",
    "\n",
    "NUM_EPOCHS = 12\n",
    "BS = 1\n",
    "NUM_TRAIN_IMAGES = int(np.round(0.8 * len(files)))\n",
    "NUM_TEST_IMAGES = len(files)-NUM_TRAIN_IMAGES\n",
    "traingen = custom_file_image_generator(trainPath,BS, \"train\" , None,highestScore, path)\n",
    "testgen = custom_file_image_generator(testpath,BS, \"train\", None,highestScore, path)\n",
    "tf.keras.backend.clear_session()\n",
    "conv_model = models.Sequential()\n",
    "#normalize pictures to [0 1]\n",
    "conv_model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "conv_model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                             input_shape=input_shape))\n",
    "conv_model.add(layers.GlobalMaxPooling2D())\n",
    "# conv_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# conv_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "conv_model.add(layers.Flatten())\n",
    "#conv_model.add(layers.Dropout(0.2))\n",
    "conv_model.add(layers.Dense(512, activation='relu'))\n",
    "conv_model.add(layers.Dense(1, activation='linear'))\n",
    "LEARNING_RATE = 1e-4\n",
    "conv_model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                   optimizer=optimizers.RMSprop(lr=LEARNING_RATE),\n",
    "                   metrics=['acc'])\n",
    "history_conv = conv_model.fit(traingen,\n",
    "                                steps_per_epoch= NUM_TRAIN_IMAGES // BS,\n",
    "                                validation_data=testgen,\n",
    "                                validation_steps = NUM_TEST_IMAGES // BS,\n",
    "                              epochs=NUM_EPOCHS)\n",
    "modelfilename = 'art2.h5'\n",
    "conv_model.save(modelfilename)\n",
    "# plt.plot(history_conv.history['loss'])\n",
    "# plt.plot(history_conv.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train loss', 'val loss'], loc='upper right')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# plt.plot(history_conv.history['acc'])\n",
    "# plt.plot(history_conv.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy (%)')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train accuracy', 'val accuracy'], loc='lower right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
